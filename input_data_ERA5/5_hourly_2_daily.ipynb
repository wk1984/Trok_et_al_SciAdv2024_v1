{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0798d3db-059f-45e4-aa8c-4b1039d25943",
   "metadata": {},
   "source": [
    "# Convert ERA5 hourly data to daily data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad9d2c2-0264-49a6-bb0d-d9ad4f92d293",
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_dir='/path/to/main_project_folder/' # edit this line\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import netCDF4 as nc4\n",
    "import re\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import multiprocessing as mp\n",
    "\n",
    "years = range(1979, 2024)\n",
    "yr_mon_args = []\n",
    "for yr in years:\n",
    "    for mon in range(1,13):\n",
    "        yr_mon_args.append((yr, mon))\n",
    "        \n",
    "pool_num = 10\n",
    "region_str_tpl = ['southcentral_north_america', 'southern_europe', 'western_russia', 'western_india', 'pacific_northwest']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e33463-9b22-4699-a69a-67e35d69f167",
   "metadata": {},
   "source": [
    "## Define functions to extract daily max, daily mean, and 00UTC values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adcbf34f-a2cb-4fd6-ab96-2dcb988906bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallel_by_yr_daily_max(yr, mon=99):\n",
    "    path_in = proj_dir+'input_data_ERA5/'+region_str+'/hourly/'+var_in+\"/\"\n",
    "    path_out = proj_dir+'input_data_ERA5/'+region_str+\"/daily/\"+var_out+\"/\"\n",
    "\n",
    "    if mon == 99:\n",
    "        f_in = '_'.join([region_str, var_in, 'hourly', str(yr)+'.nc']) \n",
    "        f_out = '_'.join([region_str, var_out, 'daily', str(yr)+'.nc'])\n",
    "    else:\n",
    "        f_in = '_'.join([region_str, var_in, 'hourly', str(yr), str(mon).zfill(2)+'.nc']) \n",
    "        f_out = '_'.join([region_str, var_out, 'daily', str(yr), str(mon).zfill(2)+'.nc']) \n",
    "\n",
    "    if os.path.exists(path_in + f_in):\n",
    "        if not os.path.exists(path_out + f_out):\n",
    "            ds = xr.open_dataset(path_in + f_in)\n",
    "\n",
    "            daily_var = ds.resample(time='24h').max(dim=\"time\", skipna=True, keep_attrs=True)\n",
    "            daily_var = daily_var.rename({var_rename: var_out})\n",
    "            daily_var.to_netcdf(path_out + f_out)\n",
    "\n",
    "def parallel_by_yr_daily_mean(yr, mon=99):\n",
    "    path_in = proj_dir+'input_data_ERA5/'+region_str+\"/hourly/\"+var_in+\"/\"\n",
    "    path_out = proj_dir+'input_data_ERA5/'+region_str+\"/daily/\"+var_out+\"/\"\n",
    "\n",
    "    if mon == 99:\n",
    "        f_in = '_'.join([region_str, var_in, 'hourly', str(yr)+'.nc']) \n",
    "        f_out = '_'.join([region_str, var_out, 'daily', str(yr)+'.nc'])\n",
    "    else:\n",
    "        f_in = '_'.join([region_str, var_in, 'hourly', str(yr), str(mon).zfill(2)+'.nc']) \n",
    "        f_out = '_'.join([region_str, var_out, 'daily', str(yr), str(mon).zfill(2)+'.nc']) \n",
    "        \n",
    "    if os.path.exists(path_in + f_in):\n",
    "        if not os.path.exists(path_out + f_out):\n",
    "            ds = xr.open_dataset(path_in + f_in)\n",
    "\n",
    "            daily_var = ds.resample(time='24h').mean(dim=\"time\", skipna=True, keep_attrs=True)\n",
    "            daily_var = daily_var.rename({var_rename: var_out})\n",
    "            daily_var.to_netcdf(path_out + f_out)\n",
    "            \n",
    "def parallel_by_yr_daily_at_00UTC(yr, mon=99):\n",
    "    path_in = proj_dir+'input_data_ERA5/'+region_str+\"/hourly/\"+var_in+\"/\"\n",
    "    path_out = proj_dir+'input_data_ERA5/'+region_str+\"/daily/\"+var_out+\"/\"\n",
    "\n",
    "    if mon == 99:\n",
    "        f_in = '_'.join([region_str, var_in, 'hourly', str(yr)+'.nc']) \n",
    "        f_out = '_'.join([region_str, var_out, 'daily', str(yr)+'.nc'])\n",
    "    else:\n",
    "        f_in = '_'.join([region_str, var_in, 'hourly', str(yr), str(mon).zfill(2)+'.nc']) \n",
    "        f_out = '_'.join([region_str, var_out, 'daily', str(yr), str(mon).zfill(2)+'.nc']) \n",
    "         \n",
    "    if os.path.exists(path_in + f_in):\n",
    "        if not os.path.exists(path_out + f_out):\n",
    "            ds = xr.open_dataset(path_in + f_in)\n",
    "            \n",
    "            midnight_UTC_timestamps = ds.time[ds.time.dt.hour == 0]\n",
    "            daily_var = ds.sel(time=midnight_UTC_timestamps)\n",
    "            daily_var['time'] = midnight_UTC_timestamps.time - np.timedelta64(1,'D')\n",
    "            daily_var = daily_var.rename({var_rename: var_out})\n",
    "            daily_var.to_netcdf(path_out + f_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e629ea9-0924-44b3-9547-78a957f8c852",
   "metadata": {},
   "source": [
    "### Daily maximum 2-meter air temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51940d1-0b13-4d9c-bb66-d9d4e827f278",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "global var_in\n",
    "var_in=\"t2m\"\n",
    "global var_rename\n",
    "var_rename=\"t2m\"\n",
    "global var_out\n",
    "var_out = \"tmax\"\n",
    "\n",
    "for region_str_loc in region_str_tpl:\n",
    "    global region_str\n",
    "    region_str = region_str_loc\n",
    "    print(region_str)\n",
    "    with mp.Pool(pool_num) as p:\n",
    "        p.starmap(parallel_by_yr_daily_max, yr_mon_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e9f529-3053-4dfd-9c24-2ba551c60bb9",
   "metadata": {},
   "source": [
    "### Daily accumulated precipitation: \n",
    "take daily value at 00 UTC as total accumulated pr (in m) for the prior day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb038332-a0d8-4446-ad95-fa6b5732c8b5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "global var_in\n",
    "var_in=\"pr\"\n",
    "global var_rename\n",
    "var_rename=\"tp\"\n",
    "global var_out\n",
    "var_out = \"pr\"\n",
    "\n",
    "for region_str_loc in ['pacific_northwest']:\n",
    "    global region_str\n",
    "    region_str = region_str_loc\n",
    "    print(region_str)\n",
    "    with mp.Pool(pool_num) as p:\n",
    "        p.starmap(parallel_by_yr_daily_at_00UTC, yr_mon_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88f2673-b4c6-4e81-8c34-8ea6e64eb5a4",
   "metadata": {},
   "source": [
    "### Daily mean soil moisture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e748ff-d9e4-47b9-96ea-29a3d8df2da6",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "global var_in\n",
    "var_in=\"swvl1\"\n",
    "global var_rename\n",
    "var_rename=\"swvl1\"\n",
    "global var_out\n",
    "var_out = \"swvl1\"\n",
    "\n",
    "for region_str_loc in region_str_tpl:\n",
    "    global region_str\n",
    "    region_str = region_str_loc\n",
    "    print(region_str)\n",
    "    with mp.Pool(pool_num) as p:\n",
    "        p.starmap(parallel_by_yr_daily_mean, yr_mon_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a557ab-e866-4837-8613-286504d4d9d1",
   "metadata": {},
   "source": [
    "### Daily mean sea-level pressure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafe9724-b171-4d00-bbbb-1343bc8ece2e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "global var_in\n",
    "var_in=\"psl\"\n",
    "global var_rename\n",
    "var_rename=\"msl\"\n",
    "global var_out\n",
    "var_out = \"psl\"\n",
    "\n",
    "for region_str_loc in region_str_tpl:\n",
    "    global region_str\n",
    "    region_str = region_str_loc\n",
    "    print(region_str)\n",
    "    with mp.Pool(pool_num) as p:\n",
    "        p.map(parallel_by_yr_daily_mean, years)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43b8b5a-2e1c-4143-bcec-9bc37a927f32",
   "metadata": {},
   "source": [
    "### Daily mean 700mb geopotential height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6255580b-f326-4fda-a3f2-20e6c6e75f60",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "global var_in\n",
    "var_in=\"z700\"\n",
    "global var_rename\n",
    "var_rename=\"z\"\n",
    "global var_out\n",
    "var_out = \"z700\"\n",
    "\n",
    "for region_str_loc in region_str_tpl:\n",
    "    global region_str\n",
    "    region_str = region_str_loc\n",
    "    print(region_str)\n",
    "    with mp.Pool(pool_num) as p:\n",
    "        p.map(parallel_by_yr_daily_mean, years)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc8f2b9-cf9f-4a13-9d0d-e88261a85c12",
   "metadata": {},
   "source": [
    "### Daily mean 500mb geopotential height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c715fe0-5cb5-45d8-ad7c-db737ba659ec",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "global var_in\n",
    "var_in=\"z500\"\n",
    "global var_rename\n",
    "var_rename=\"z\"\n",
    "global var_out\n",
    "var_out = \"z500\"\n",
    "\n",
    "for region_str_loc in region_str_tpl:\n",
    "    global region_str\n",
    "    region_str = region_str_loc\n",
    "    print(region_str)\n",
    "    with mp.Pool(pool_num) as p:\n",
    "        p.map(parallel_by_yr_daily_mean, years)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4275be0-d653-4941-9137-21a252257512",
   "metadata": {},
   "source": [
    "### Daily mean 250mb geopotential height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d831c38f-98cb-4bff-889e-ba7dde393dac",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "global var_in\n",
    "var_in=\"z250\"\n",
    "global var_rename\n",
    "var_rename=\"z\"\n",
    "global var_out\n",
    "var_out = \"z250\"\n",
    "\n",
    "for region_str_loc in region_str_tpl:\n",
    "    global region_str\n",
    "    region_str = region_str_loc\n",
    "    print(region_str)\n",
    "    with mp.Pool(pool_num) as p:\n",
    "        p.map(parallel_by_yr_daily_mean, years)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
